services:

  jupyter:
    build:
      context: .
      dockerfile:
        
        Dockerfile.jupyter-cuda-pt
        
    container_name: jupyter
    ports: 
      - "8888:8888"
    volumes:
      - ~/.config/rclone:/home/jovyan/.config/rclone
      - ~/UC-OBJECT:/home/jovyan/work/UC-OBJECT
    environment:
      - JUPYTER_ENABLE_LAB=yes
      - PYTHONPATH=/home/jovyan/work/UC-OBJECT
      - MLFLOW_TRACKING_URI=http://mlflow:8000
    
      - HF_HOME=${HF_HOME}
      - HF_TOKEN_PATH=${HF_TOKEN_PATH}
      - HF_TOKEN=${HF_TOKEN}
      
    
    runtime: nvidia
    
    restart: always 
    shm_size: 2g
    cap_add:
      - SYS_ADMIN
    devices:
      - /dev/fuse:/dev/fuse
    security_opt:
      - apparmor:unconfined
    entrypoint: ["/usr/local/bin/start-jupyter-and-mounts.sh"]

  mlflow:
    build:
       context: . 
       dockerfile: Dockerfile.mlflow
    container_name: mlflow
    restart: always
    ports:
      - "8000:8000"
    environment:
      - MLFLOW_S3_ENDPOINT_URL=${S3_ENDPOINT_URL}
      - AWS_ACCESS_KEY_ID=${S3_ACCESS_KEY}
      - AWS_SECRET_ACCESS_KEY=${S3_SECRET_ACCESS_KEY}
      - AWS_REQUEST_CHECKSUM_CALCULATION=WHEN_REQUIRED
      - AWS_RESPONSE_CHECKSUM_VALIDATION=WHEN_REQUIRED  
    volumes:
      - /mnt/metrics:/mlflow/mlruns 
    command:
      - mlflow
      - server
      - --backend-store-uri=/mlflow/mlruns
      - --artifacts-destination=s3://UC-OBJECT-mlflow-artifacts
      - --serve-artifacts
      - --host=0.0.0.0
      - --port=8000